How to Use These Models
A. Local Deployment

Download model weights from Hugging Face.

Use an inference runner (e.g., WhisperCpp, Ollama, Transformers, GPT-4All).

Integrate into your chatbot code (Python, Node.js, etc.) using inference APIs.

B. Cloud Deployment

Use a free API provider or credit system.

Call the model endpoints from your chatbot backend.

Handle user session context and conversation history in your app logic.
